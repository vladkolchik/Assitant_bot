"""
–ú–æ–¥—É–ª—å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é Whisper –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É ChatGPT
"""
import asyncio
import os
import tempfile
import time
from pathlib import Path
from aiogram import Router, F
from aiogram.types import CallbackQuery, Message, Audio, Voice, VideoNote, Document
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

from .config import MODULE_CONFIG, OPENAI_API_KEY
from .messages import MESSAGES

# –°–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥—É–ª—è
class VoiceAssistantStates(StatesGroup):
    waiting_for_audio = State()

voice_assistant_router = Router()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = bool(OPENAI_API_KEY)
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    else:
        openai_client = None
except ImportError:
    OPENAI_AVAILABLE = False
    openai_client = None
    print("‚ö†Ô∏è OpenAI library not installed. Run: pip install openai")

def get_back_menu():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
    ])

def format_file_size(size_bytes: int) -> float:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë"""
    return round(size_bytes / (1024 * 1024), 2)

def get_file_extension(filename: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    return Path(filename).suffix.lower() if filename else ''

@voice_assistant_router.callback_query(F.data == "voice_assistant")
async def activate_voice_assistant(callback: CallbackQuery, state: FSMContext):
    """–ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    if not callback.message:
        return
        
    if not OPENAI_AVAILABLE:
        await callback.message.edit_text(  # type: ignore
            MESSAGES["not_configured"], 
            reply_markup=get_back_menu()
        )
        return
    
    await state.set_state(VoiceAssistantStates.waiting_for_audio)
    await callback.message.edit_text(  # type: ignore
        MESSAGES["welcome"],
        reply_markup=get_back_menu()
    )
    await callback.answer("üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")

@voice_assistant_router.message(StateFilter(VoiceAssistantStates.waiting_for_audio), F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if not OPENAI_AVAILABLE or not openai_client or not message.voice:
        return
    
    await process_audio_with_chatgpt(message, message.voice.file_id, "voice.ogg", message.voice.file_size or 0)

@voice_assistant_router.message(StateFilter(VoiceAssistantStates.waiting_for_audio), F.audio)
async def handle_audio_file(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.audio:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if message.audio.file_size and message.audio.file_size > MODULE_CONFIG['max_file_size']:
        size_mb = format_file_size(message.audio.file_size)
        await message.reply(
            MESSAGES["file_too_large"].format(size=size_mb),
            reply_markup=get_back_menu()
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
    filename = message.audio.file_name or "audio.mp3"
    file_ext = get_file_extension(filename)
    if file_ext not in MODULE_CONFIG['supported_formats']:
        await message.reply(
            MESSAGES["unsupported_format"].format(format=file_ext),
            reply_markup=get_back_menu()
        )
        return
    
    await process_audio_with_chatgpt(message, message.audio.file_id, filename, message.audio.file_size or 0)

@voice_assistant_router.message(StateFilter(VoiceAssistantStates.waiting_for_audio), F.video_note)
async def handle_video_note(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—É–∂–æ—á–∫–æ–≤ (–≤–∏–¥–µ–æ—Å–æ–æ–±—â–µ–Ω–∏–π)"""
    if not OPENAI_AVAILABLE or not openai_client or not message.video_note:
        return
    
    await process_audio_with_chatgpt(message, message.video_note.file_id, "video_note.mp4", message.video_note.file_size or 0)

@voice_assistant_router.message(StateFilter(VoiceAssistantStates.waiting_for_audio), F.document)
async def handle_document_audio(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.document:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª
    filename = message.document.file_name or ""
    file_ext = get_file_extension(filename)
    if file_ext not in MODULE_CONFIG['supported_formats']:
        await message.reply(
            MESSAGES["send_audio"],
            reply_markup=get_back_menu()
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if message.document.file_size and message.document.file_size > MODULE_CONFIG['max_file_size']:
        size_mb = format_file_size(message.document.file_size)
        await message.reply(
            MESSAGES["file_too_large"].format(size=size_mb),
            reply_markup=get_back_menu()
        )
        return
    
    await process_audio_with_chatgpt(message, message.document.file_id, filename, message.document.file_size or 0)

async def process_audio_with_chatgpt(message: Message, file_id: str, filename: str, file_size: int):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è + ChatGPT"""
    start_time = time.time()
    
    # –≠—Ç–∞–ø 1: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    transcription_text = ""
    detected_language = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    try:
        # –≠—Ç–∞–ø 2: –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –æ—Ç Telegram
        file_info = await message.bot.get_file(file_id)
        if not file_info.file_path:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        file_ext = get_file_extension(filename)
        with tempfile.NamedTemporaryFile(suffix=file_ext, delete=False) as temp_file:
            temp_path = temp_file.name
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            await message.bot.download_file(file_info.file_path, temp_path)
        
        # –≠—Ç–∞–ø 3: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —á–µ—Ä–µ–∑ Whisper
        await processing_msg.edit_text(MESSAGES["transcribing"])
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Whisper API
        with open(temp_path, 'rb') as audio_file:
            language = MODULE_CONFIG['whisper_language'] if MODULE_CONFIG['whisper_language'] != 'auto' else None
            
            transcription = await asyncio.wait_for(
                asyncio.to_thread(
                    openai_client.audio.transcriptions.create,  # type: ignore
                    model=MODULE_CONFIG['whisper_model'],
                    file=audio_file,
                    language=language,
                    temperature=MODULE_CONFIG['whisper_temperature']
                ),
                timeout=MODULE_CONFIG['whisper_timeout']
            )
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(temp_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        if not transcription.text or transcription.text.strip() == "":
            await processing_msg.edit_text(
                MESSAGES["no_speech"],
                reply_markup=get_back_menu()
            )
            return
        
        transcription_text = transcription.text.strip()
        detected_language = getattr(transcription, 'language', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        
        # –≠—Ç–∞–ø 4: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ ChatGPT
        await processing_msg.edit_text(MESSAGES["chatgpt_thinking"])
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ ChatGPT API
        chatgpt_response = await asyncio.wait_for(
            asyncio.to_thread(
                openai_client.chat.completions.create,  # type: ignore
                model=MODULE_CONFIG['chatgpt_model'],
                messages=[
                    {"role": "system", "content": MODULE_CONFIG['system_prompt']},
                    {"role": "user", "content": transcription_text}
                ],
                max_tokens=MODULE_CONFIG['chatgpt_max_tokens'],
                temperature=MODULE_CONFIG['chatgpt_temperature']
            ),
            timeout=MODULE_CONFIG['chatgpt_timeout']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç ChatGPT
        ai_response = chatgpt_response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        total_duration = round(time.time() - start_time, 1)
        file_size_mb = format_file_size(file_size)
        
        final_result = MESSAGES["final_result"].format(
            transcription=transcription_text,
            ai_response=ai_response,
            total_duration=total_duration,
            language=detected_language,
            file_size=file_size_mb
        )
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await processing_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await message.reply(
            final_result,
            reply_markup=get_back_menu()
        )
        
    except asyncio.TimeoutError:
        await processing_msg.edit_text(
            MESSAGES["error_timeout"],
            reply_markup=get_back_menu()
        )
        
    except Exception as e:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        try:
            if 'temp_path' in locals():
                os.unlink(temp_path)
        except:
            pass
        
        error_text = str(e)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏
        if transcription_text:
            # –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ ChatGPT
            await processing_msg.edit_text(
                MESSAGES["chatgpt_failed"].format(
                    transcription=transcription_text,
                    error=error_text
                ),
                reply_markup=get_back_menu()
            )
        elif "download" in error_text.lower():
            await processing_msg.edit_text(
                MESSAGES["error_download"].format(error=error_text),
                reply_markup=get_back_menu()
            )
        else:
            # –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            await processing_msg.edit_text(
                MESSAGES["transcription_failed"].format(error=error_text),
                reply_markup=get_back_menu()
            )

@voice_assistant_router.message(StateFilter(VoiceAssistantStates.waiting_for_audio))
async def handle_non_audio_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ-–∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    await message.reply(
        MESSAGES["send_audio"],
        reply_markup=get_back_menu()
    )

@voice_assistant_router.callback_query(F.data == "main_menu", StateFilter(VoiceAssistantStates.waiting_for_audio))
async def exit_voice_assistant_mode(callback: CallbackQuery, state: FSMContext):
    """–í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    await state.clear()
    await callback.answer(MESSAGES["welcome_back"]) 