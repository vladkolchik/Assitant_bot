"""
ChatGPT + Whisper –º–æ–¥—É–ª—å –¥–ª—è Telegram –±–æ—Ç–∞
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI API –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∞—É–¥–∏–æ
"""
import asyncio
import os
import re
from collections import defaultdict, deque
from pathlib import Path
from aiogram import Router, F, Bot
from aiogram.types import CallbackQuery, Message
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

from .config import MODULE_CONFIG, OPENAI_API_KEY
from .messages import MESSAGES
from .services import transcribe_voice_message, transcribe_video_note, transcribe_audio_file
from .image_utils import create_image_processor
from .memory_service import memory_service

# –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (–≤ RAM, –æ—á–∏—â–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ)
session_memory = defaultdict(lambda: deque(maxlen=10))  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è MEM0_ENABLED –≤ .env —Ñ–∞–π–ª–µ
async def toggle_mem0_setting() -> bool:
    """
    –ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç MEM0_ENABLED –≤ .env —Ñ–∞–π–ª–µ –º–æ–¥—É–ª—è
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (True/False)
    """
    env_file = Path(__file__).parent / '.env'
    
    try:
        if env_file.exists():
            content = env_file.read_text(encoding='utf-8')
        else:
            content = ""
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É MEM0_ENABLED
        if 'MEM0_ENABLED=' in content:
            # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
            if 'MEM0_ENABLED=true' in content:
                new_content = content.replace('MEM0_ENABLED=true', 'MEM0_ENABLED=false')
                new_value = False
            else:
                new_content = content.replace('MEM0_ENABLED=false', 'MEM0_ENABLED=true')
                new_value = True
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            new_content = content + '\n# Mem0 –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å\nMEM0_ENABLED=false\n'
            new_value = False
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        env_file.write_text(new_content, encoding='utf-8')
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥—É–ª—è –≤ runtime
        MODULE_CONFIG['mem0_enabled'] = new_value
        
        return new_value
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è MEM0_ENABLED: {e}")
        return MODULE_CONFIG.get('mem0_enabled', False)

def get_session_context(user_id: str, current_message: str) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
    """
    history = list(session_memory.get(user_id, []))
    if not history:
        return ""
    
    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –∑–∞–ø–∏—Å–µ–π (3 –ø–∞—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤)
    recent_history = history[-6:]
    context_lines = []
    
    for entry in recent_history:
        context_lines.append(entry)
    
    if context_lines:
        return "–ö–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã:\n" + "\n".join(context_lines)
    
    return ""

def save_to_session_memory(user_id: str, user_message: str, ai_response: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∏–∞–ª–æ–≥ –≤ —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å
    """
    session_memory[user_id].append(f"üë§: {user_message}")
    session_memory[user_id].append(f"ü§ñ: {ai_response}")

def clear_session_memory(user_id: str) -> bool:
    """
    –û—á–∏—â–∞–µ—Ç —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    try:
        if user_id in session_memory:
            session_memory[user_id].clear()
        return True
    except Exception:
        return False

def get_session_memory_stats(user_id: str) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
    """
    history = session_memory.get(user_id, deque())
    return {
        'messages_count': len(history) // 2,  # –ü–∞—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤
        'total_entries': len(history),
        'max_capacity': history.maxlen
    }

# –°–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥—É–ª—è
class ChatGPTStates(StatesGroup):
    waiting_for_message = State()

chatgpt_router = Router()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = bool(OPENAI_API_KEY)
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    else:
        openai_client = None
except ImportError:
    OPENAI_AVAILABLE = False
    openai_client = None
    print("‚ö†Ô∏è OpenAI library not installed. Run: pip install openai")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
try:
    if MODULE_CONFIG['vision_enabled']:
        image_processor = create_image_processor(MODULE_CONFIG)
        VISION_AVAILABLE = True
    else:
        image_processor = None
        VISION_AVAILABLE = False
except ImportError:
    print("‚ö†Ô∏è PIL (Pillow) library not installed. Vision API disabled. Run: pip install Pillow")
    image_processor = None
    VISION_AVAILABLE = False

def get_back_menu():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é"""
    keyboard = []
    
    # –ü–µ—Ä–≤—ã–π —Ä—è–¥: –∫–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é
    memory_row = []
    
    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
    if MODULE_CONFIG.get('mem0_enabled', False):
        memory_row.append(InlineKeyboardButton(text="üíæ‚û°Ô∏èüìù –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è", callback_data="toggle_memory_mode"))
    else:
        memory_row.append(InlineKeyboardButton(text="üìù‚û°Ô∏èüíæ –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è", callback_data="toggle_memory_mode"))
    
    # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏ (–≤—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º)
    memory_row.append(InlineKeyboardButton(text="üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å", callback_data="clear_memory"))
    
    keyboard.append(memory_row)
    
    # –í—Ç–æ—Ä–æ–π —Ä—è–¥: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–∫—É—â–µ–º —Ä–µ–∂–∏–º–µ –ø–∞–º—è—Ç–∏
    if MODULE_CONFIG.get('mem0_enabled', False):
        keyboard.append([InlineKeyboardButton(text="üíæ –†–µ–∂–∏–º: –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (Mem0)", callback_data="memory_info")])
    else:
        keyboard.append([InlineKeyboardButton(text="üìù –†–µ–∂–∏–º: –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (RAM)", callback_data="memory_info")])
    
    # –¢—Ä–µ—Ç–∏–π —Ä—è–¥: –≤–æ–∑–≤—Ä–∞—Ç –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    keyboard.append([InlineKeyboardButton(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")])
    
    return InlineKeyboardMarkup(inline_keyboard=keyboard)

def get_token_params(model: str, max_tokens: int) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π OpenAI
    
    Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏) –∏—Å–ø–æ–ª—å–∑—É—é—Ç max_completion_tokens
    –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç max_tokens
    """
    # Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏)
    if any(model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        return {'max_completion_tokens': max_tokens}
    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (gpt-3.5-turbo, gpt-4, gpt-4o –∏ —Ç.–¥.)
    else:
        return {'max_tokens': max_tokens}

def get_api_params(model: str, messages: list, temperature: float, max_tokens: int, timeout: int) -> dict:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI API —Å —É—á–µ—Ç–æ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏
    
    Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç system —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä temperature
    """
    base_params = {
        'model': model,
        'timeout': timeout
    }
    
    # Reasoning-–º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    if any(model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        # –£–±–∏—Ä–∞–µ–º system —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π (–æ–Ω–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è)
        user_messages = [msg for msg in messages if msg.get('role') != 'system']
        if not user_messages:
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å —Ç–æ–ª—å–∫–æ system —Å–æ–æ–±—â–µ–Ω–∏—è, –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ user —Å–æ–æ–±—â–µ–Ω–∏–µ
            user_messages = [{'role': 'user', 'content': messages[-1]['content']}]
        
        base_params.update({
            'messages': user_messages,
            **get_token_params(model, max_tokens)
            # temperature –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
        })
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        base_params.update({
            'messages': messages,
            'temperature': temperature,
            **get_token_params(model, max_tokens)
        })
    
    return base_params

@chatgpt_router.callback_query(F.data == "chatgpt_mode")
async def activate_chatgpt(callback: CallbackQuery, state: FSMContext):
    """–ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ ChatGPT"""
    if not callback.message:
        return
        
    if not OPENAI_AVAILABLE:
        await callback.message.edit_text(  # type: ignore
            MESSAGES["not_configured"], 
            reply_markup=get_back_menu()
        )
        await callback.answer("–ú–æ–¥—É–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    await state.set_state(ChatGPTStates.waiting_for_message)
    
    await callback.message.edit_text(  # type: ignore
        MESSAGES["activation"],
        reply_markup=get_back_menu()
    )
    await callback.answer("ü§ñ ChatGPT –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.text)
async def handle_chatgpt_message(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è ChatGPT"""
    if not OPENAI_AVAILABLE or not openai_client or not message.text:
        return
    
    if not message.from_user:
        return
        
    user_id = str(message.from_user.id)
    user_text = message.text
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±–æ—Ç –¥—É–º–∞–µ—Ç
    thinking_msg = await message.reply(MESSAGES["thinking"])
    
    try:
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏
        memory_context = ""
        context_count = 0
        context_source = ""
        
        if MODULE_CONFIG.get('mem0_enabled', False):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (Mem0)
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è
                memory_context = await memory_service.search_relevant_memories(user_id, user_text, limit=3)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                user_profile = await memory_service.get_user_profile(user_id)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                full_context_parts = []
                if user_profile:
                    full_context_parts.append(user_profile)
                if memory_context:
                    full_context_parts.append(memory_context)
                
                memory_context = "\n\n".join(full_context_parts)
                
                if memory_context:
                    context_count = len(memory_context.split('\n')) - 1  # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
                    context_source = "–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π"
                    # print(f"üß† –ó–∞–≥—Ä—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏ –¥–ª—è {user_id}: {context_count} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π")
                    # print(f"üîç –û–¢–õ–ê–î–ö–ê - –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {memory_context}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –ø–∞–º—è—Ç–∏: {e}")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (RAM)
            try:
                memory_context = get_session_context(user_id, user_text)
                if memory_context:
                    session_stats = get_session_memory_stats(user_id)
                    context_count = session_stats['messages_count']
                    context_source = "—Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π"
                    # print(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Å–µ—Å—Å–∏–∏ –¥–ª—è {user_id}: {context_count} –¥–∏–∞–ª–æ–≥–æ–≤")
                    # print(f"üîç –û–¢–õ–ê–î–ö–ê - –°–µ—Å—Å–∏–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {memory_context}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        system_content = "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã."
        
        # –î–ª—è reasoning-–º–æ–¥–µ–ª–µ–π –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        user_content = user_text
        if memory_context:
            user_content = f"{memory_context}\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_text}"
        
        api_messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content}
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await thinking_msg.delete()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞–º—è—Ç–∏
        response_text = f"ü§ñ **ChatGPT:**\n\n{ai_response}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        if context_count > 0 and context_source:
            if MODULE_CONFIG.get('mem0_enabled', False):
                response_text += f"\n\n{MESSAGES['memory_context_loaded'].format(count=context_count)}"
            else:
                response_text += f"\n\n{MESSAGES['session_context_loaded'].format(count=context_count)}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI
        await message.reply(response_text, reply_markup=get_back_menu())
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥ –≤ –ø–∞–º—è—Ç—å
        if MODULE_CONFIG.get('mem0_enabled', False):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (Mem0)
            try:
                conversation = [
                    {"role": "user", "content": user_text},
                    {"role": "assistant", "content": ai_response}
                ]
                # print(f"üíæ –û–¢–õ–ê–î–ö–ê - –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å: {conversation}")
                await memory_service.add_conversation(user_id, conversation)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å: {e}")
        else:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (RAM)
            try:
                save_to_session_memory(user_id, user_text, ai_response)
                # print(f"üìù –û–¢–õ–ê–î–ö–ê - –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å: {user_text} -> {ai_response[:50]}...")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å: {e}")
        
    except asyncio.TimeoutError:
        await thinking_msg.edit_text(MESSAGES["error_timeout"])
        
    except Exception as e:
        error_text = MESSAGES["error_api"].format(error=str(e))
        await thinking_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.voice)
async def handle_voice_message(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if not OPENAI_AVAILABLE or not openai_client or not message.voice:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        transcription, method, error = await transcribe_voice_message(bot, message.voice)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.video_note)
async def handle_video_note(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—É–∂–æ—á–∫–æ–≤ (–≤–∏–¥–µ–æ –∑–∞–º–µ—Ç–æ–∫)"""
    if not OPENAI_AVAILABLE or not openai_client or not message.video_note:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∫—Ä—É–∂–æ—á–µ–∫
        transcription, method, error = await transcribe_video_note(bot, message.video_note)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "‚≠ï –ö—Ä—É–∂–æ—á–µ–∫")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.audio)
async def handle_audio_file(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.audio:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
        transcription, method, error = await transcribe_audio_file(bot, message.audio)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "üéµ –ê—É–¥–∏–æ —Ñ–∞–π–ª")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

async def _process_transcribed_text(message: Message, transcription: str, audio_type: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ ChatGPT"""
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ ChatGPT –¥—É–º–∞–µ—Ç
    thinking_msg = await message.reply(MESSAGES["thinking"])
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        api_messages = [
            {"role": "system", "content": "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã."},
            {"role": "user", "content": transcription}
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await thinking_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        response_text = f"{audio_type} ‚Üí ü§ñ **ChatGPT:**\n\n"
        response_text += f"*–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:* {transcription}\n\n"
        response_text += f"*–û—Ç–≤–µ—Ç:* {ai_response}"
        
        await message.reply(response_text, reply_markup=get_back_menu())
        
    except asyncio.TimeoutError:
        await thinking_msg.edit_text(MESSAGES["error_timeout"])
        
    except Exception as e:
        error_text = MESSAGES["error_api"].format(error=str(e))
        await thinking_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.photo)
async def handle_image_message(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Vision API"""
    if not OPENAI_AVAILABLE or not openai_client or not message.photo:
        return
    
    if not VISION_AVAILABLE or not image_processor:
        await message.reply(
            "üì∑ **Vision API –æ—Ç–∫–ª—é—á–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
            "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            "‚Ä¢ –ú–æ–¥—É–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n"
            "‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Vision API\n"
            "‚Ä¢ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ PIL\n\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏: gpt-4o, gpt-4o-mini, gpt-4-vision-preview",
            reply_markup=get_back_menu()
        )
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    processing_msg = await message.reply("üñºÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        # –ë–µ—Ä–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–∏–≤—ã—Å—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        photo = message.photo[-1]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        file_stream = await bot.download(photo)  # type: ignore
        if not file_stream:
            await processing_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            return
        
        image_bytes = file_stream.read()  # type: ignore
        file_stream.close()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è API
        base64_image, image_info = image_processor.prepare_image_for_api(
                            image_bytes, MODULE_CONFIG['vision_quality']
        )
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if MODULE_CONFIG['vision_cost_warnings']:
            cost_warning = image_processor.get_cost_warning(image_info, MODULE_CONFIG['model'])
            await processing_msg.edit_text(
                f"üñºÔ∏è **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:**\n\n{cost_warning}\n\nü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é..."
            )
        else:
            await processing_msg.edit_text("ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Vision API
        user_text = message.caption if message.caption else "–û–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –≤–∏–¥–∏—Ç–µ –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."
        
        api_messages = [
            {
                "role": "system", 
                "content": "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –ø–æ–¥—Ä–æ–±–Ω—ã –≤ –æ–ø–∏—Å–∞–Ω–∏—è—Ö."
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_text},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                            "detail": MODULE_CONFIG['vision_quality']
                        }
                    }
                ]
            }
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏ (–±–µ–∑ temperature –¥–ª—è reasoning –º–æ–¥–µ–ª–µ–π)
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ Vision API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        await processing_msg.delete()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        response_text = f"üñºÔ∏è **Vision API:**\n\n"
        if message.caption:
            response_text += f"*–í–∞—à –≤–æ–ø—Ä–æ—Å:* {message.caption}\n\n"
        response_text += f"*–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:* {ai_response}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö –≤ –∫–æ–Ω—Ü–µ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if MODULE_CONFIG['vision_cost_warnings']:
            estimated_cost = image_processor.estimate_cost_usd(image_info['estimated_tokens'], MODULE_CONFIG['model'])
            response_text += f"\n\nüí∞ *–ó–∞—Ç—Ä–∞—á–µ–Ω–æ: ~${estimated_cost:.4f} (~{image_info['estimated_tokens']} —Ç–æ–∫–µ–Ω–æ–≤)*"
        
        await message.reply(response_text, reply_markup=get_back_menu())
        
    except Exception as e:
        error_text = f"‚ùå **–û—à–∏–±–∫–∞ Vision API:**\n{str(e)}\n\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n‚Ä¢ –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç API\n‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        await processing_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message))
async def handle_unsupported_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ ChatGPT"""
    await message.reply(
        MESSAGES["unsupported_format"],
        reply_markup=get_back_menu()
    )

@chatgpt_router.callback_query(F.data == "clear_memory", StateFilter(ChatGPTStates.waiting_for_message))
async def clear_user_memory(callback: CallbackQuery):
    """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π)"""
    if not callback.message:
        return
    
    user_id = str(callback.from_user.id)
    
    try:
        if MODULE_CONFIG.get('mem0_enabled', False):
            # –û—á–∏—â–∞–µ–º –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (Mem0)
            success = await memory_service.clear_user_memory(user_id)
            
            if success:
                await callback.message.edit_text(  # type: ignore
                    MESSAGES["memory_cleared"],
                    reply_markup=get_back_menu()
                )
                await callback.answer("üóëÔ∏è –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞!")
            else:
                await callback.message.edit_text(  # type: ignore
                    MESSAGES["memory_clear_error"],
                    reply_markup=get_back_menu()
                )
                await callback.answer("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏")
        else:
            # –û—á–∏—â–∞–µ–º —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (RAM)
            success = clear_session_memory(user_id)
            
            if success:
                await callback.message.edit_text(  # type: ignore
                    MESSAGES["session_memory_cleared"],
                    reply_markup=get_back_menu()
                )
                await callback.answer("üóëÔ∏è –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞!")
            else:
                await callback.message.edit_text(  # type: ignore
                    MESSAGES["memory_clear_error"],
                    reply_markup=get_back_menu()
                )
                await callback.answer("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
        await callback.message.edit_text(  # type: ignore
            MESSAGES["memory_clear_error"],
            reply_markup=get_back_menu()
        )
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏")

@chatgpt_router.callback_query(F.data == "toggle_memory_mode", StateFilter(ChatGPTStates.waiting_for_message))
async def toggle_memory_mode(callback: CallbackQuery):
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –ø–∞–º—è—Ç–∏ (–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è ‚áÑ —Å–µ—Å—Å–∏–æ–Ω–Ω–∞—è)"""
    if not callback.message:
        return
    
    try:
        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –ø–∞–º—è—Ç–∏
        new_mem0_state = await toggle_mem0_setting()
        
        if new_mem0_state:
            mode_name = "–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (Mem0)"
            icon = "üíæ"
        else:
            mode_name = "—Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–º—è—Ç—å (RAM)"
            icon = "üìù"
        
        await callback.message.edit_text(  # type: ignore
            MESSAGES["memory_mode_switched"].format(mode=mode_name),
            reply_markup=get_back_menu()
        )
        await callback.answer(f"{icon} –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ {mode_name}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞ –ø–∞–º—è—Ç–∏: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞")

@chatgpt_router.callback_query(F.data == "memory_info", StateFilter(ChatGPTStates.waiting_for_message))
async def show_memory_info(callback: CallbackQuery):
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏"""
    if not callback.message:
        return
    
    user_id = str(callback.from_user.id)
    
    try:
        if MODULE_CONFIG.get('mem0_enabled', False):
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
            memory_stats = memory_service.get_memory_stats()
            memory_status = "‚úÖ –í–∫–ª—é—á–µ–Ω–∞" if memory_stats.get('enabled', False) else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
            memory_provider = memory_stats.get('provider', 'N/A')
            
            info_text = MESSAGES["memory_info_detailed"].format(
                mode="üíæ –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (Mem0)",
                status=memory_status,
                provider=memory_provider,
                description="–°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Mem0 API –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤."
            )
        else:
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
            session_stats = get_session_memory_stats(user_id)
            
            info_text = MESSAGES["memory_info_detailed"].format(
                mode="üìù –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (RAM)",
                status="‚úÖ –ê–∫—Ç–∏–≤–Ω–∞",
                provider=f"RAM (–ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ)",
                description=f"–•—Ä–∞–Ω–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞. –¢–µ–∫—É—â–∏–π –¥–∏–∞–ª–æ–≥: {session_stats['messages_count']} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {session_stats['max_capacity']} –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö."
            )
        
        await callback.message.edit_text(  # type: ignore
            info_text,
            reply_markup=get_back_menu()
        )
        await callback.answer("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–º—è—Ç–∏: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

@chatgpt_router.callback_query(F.data == "main_menu", StateFilter(ChatGPTStates.waiting_for_message))
async def exit_chatgpt_mode(callback: CallbackQuery, state: FSMContext):
    """–í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ ChatGPT"""
    if not callback.message:
        return
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    from keyboards.main_menu import get_main_menu
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    await callback.message.edit_text("üìã –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=get_main_menu())  # type: ignore
    await callback.answer(MESSAGES["welcome_back"])

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.text.startswith("/chatgpt_info"))
async def show_module_info(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥—É–ª—è"""
    current_model = MODULE_CONFIG['model']
    effective_tokens = MODULE_CONFIG['max_tokens']
    temperature = MODULE_CONFIG['temperature']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
    if any(current_model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        temp_note = "(–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–ª—è reasoning)"
        token_note = f"(max_completion_tokens)"
        display_tokens = MODULE_CONFIG['max_completion_tokens']
    else:
        temp_note = ""
        token_note = "(max_tokens)"
        display_tokens = MODULE_CONFIG['original_max_tokens']
    
    info_text = MESSAGES["model_info"].format(
        model=current_model,
        temperature=temperature,
        temp_note=temp_note,
        max_tokens=display_tokens,
        token_note=token_note,
        whisper_mode=MODULE_CONFIG['whisper_mode'],
        whisper_language=MODULE_CONFIG['whisper_language'],
        max_size=MODULE_CONFIG['max_audio_size_mb'],
        max_duration=MODULE_CONFIG['max_audio_duration_sec'] // 60  # –í –º–∏–Ω—É—Ç–∞—Ö
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏ (–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π)
    if MODULE_CONFIG.get('mem0_enabled', False):
        memory_stats = memory_service.get_memory_stats()
        memory_status = "‚úÖ –í–∫–ª—é—á–µ–Ω–∞" if memory_stats.get('enabled', False) else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
        memory_provider = memory_stats.get('provider', 'N/A')
        
        info_text += f"\n\n**üíæ –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (Mem0):**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {memory_status}\n"
        info_text += f"‚Ä¢ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {memory_provider}\n"
        info_text += f"‚Ä¢ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏"
    else:
        user_id = str(message.from_user.id) if message.from_user else "unknown"
        session_stats = get_session_memory_stats(user_id)
        
        info_text += f"\n\n**üìù –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (RAM):**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞\n"
        info_text += f"‚Ä¢ –•—Ä–∞–Ω–µ–Ω–∏–µ: –ª–æ–∫–∞–ª—å–Ω–æ–µ (RAM)\n"
        info_text += f"‚Ä¢ –î–∏–∞–ª–æ–≥–æ–≤ –≤ –ø–∞–º—è—Ç–∏: {session_stats['messages_count']}/{session_stats['max_capacity']}"
    
    await message.reply(info_text, reply_markup=get_back_menu())

@chatgpt_router.message(F.text.startswith("/chatgpt_info"))
async def show_module_info_outside(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥—É–ª–µ –≤–Ω–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
    if not OPENAI_AVAILABLE:
        await message.reply(MESSAGES["not_configured"])
        return
        
    current_model = MODULE_CONFIG['model']
    effective_tokens = MODULE_CONFIG['max_tokens']
    temperature = MODULE_CONFIG['temperature']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
    if any(current_model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        temp_note = "(–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–ª—è reasoning)"
        token_note = f"(max_completion_tokens)"
        display_tokens = MODULE_CONFIG['max_completion_tokens']
    else:
        temp_note = ""
        token_note = "(max_tokens)"
        display_tokens = MODULE_CONFIG['original_max_tokens']
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ Vision API –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –≤—ã–∑–æ–≤–∞
    vision_status = "‚úÖ –í–∫–ª—é—á–µ–Ω" if MODULE_CONFIG['vision_enabled'] and VISION_AVAILABLE else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω"
    vision_quality = MODULE_CONFIG['vision_quality'] if MODULE_CONFIG['vision_enabled'] else "N/A"
    
    info_text = MESSAGES["model_info"].format(
        model=current_model,
        temperature=temperature,
        temp_note=temp_note,
        max_tokens=display_tokens,
        token_note=token_note,
        whisper_mode=MODULE_CONFIG['whisper_mode'],
        whisper_language=MODULE_CONFIG['whisper_language'],
        max_size=MODULE_CONFIG['max_audio_size_mb'],
        max_duration=MODULE_CONFIG['max_audio_duration_sec'] // 60  # –í –º–∏–Ω—É—Ç–∞—Ö
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Vision API
    info_text += f"\n\n**Vision API (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è):**\n"
    info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {vision_status}\n"
    info_text += f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ: {vision_quality}\n"
    info_text += f"‚Ä¢ –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {MODULE_CONFIG['max_image_size_mb']} –ú–ë\n"
    info_text += f"‚Ä¢ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö: {'‚úÖ' if MODULE_CONFIG['vision_cost_warnings'] else '‚ùå'}"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏ (–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–π)
    if MODULE_CONFIG.get('mem0_enabled', False):
        memory_stats = memory_service.get_memory_stats()
        memory_status = "‚úÖ –í–∫–ª—é—á–µ–Ω–∞" if memory_stats.get('enabled', False) else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
        memory_provider = memory_stats.get('provider', 'N/A')
        
        info_text += f"\n\n**üíæ –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (Mem0):**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {memory_status}\n"
        info_text += f"‚Ä¢ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {memory_provider}\n"
        info_text += f"‚Ä¢ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤"
    else:
        info_text += f"\n\n**üìù –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å (RAM):**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: ‚úÖ –î–æ—Å—Ç—É–ø–Ω–∞\n"
        info_text += f"‚Ä¢ –•—Ä–∞–Ω–µ–Ω–∏–µ: –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–æ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏\n"
        info_text += f"‚Ä¢ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –≤–Ω—É—Ç—Ä–∏ –º–æ–¥—É–ª—è –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"
    
    info_text += f"\n\nüí° –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –º–æ–¥—É–ª—å: /start ‚Üí ü§ñ ChatGPT"
    
    await message.reply(info_text) 