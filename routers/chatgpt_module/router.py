"""
ChatGPT + Whisper –º–æ–¥—É–ª—å –¥–ª—è Telegram –±–æ—Ç–∞
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI API –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∞—É–¥–∏–æ
"""
import asyncio
from aiogram import Router, F, Bot
from aiogram.types import CallbackQuery, Message
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

from .config import MODULE_CONFIG, OPENAI_API_KEY
from .messages import MESSAGES
from .services import transcribe_voice_message, transcribe_video_note, transcribe_audio_file

# –°–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥—É–ª—è
class ChatGPTStates(StatesGroup):
    waiting_for_message = State()

chatgpt_router = Router()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = bool(OPENAI_API_KEY)
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    else:
        openai_client = None
except ImportError:
    OPENAI_AVAILABLE = False
    openai_client = None
    print("‚ö†Ô∏è OpenAI library not installed. Run: pip install openai")

def get_back_menu():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
    ])

def get_token_params(model: str, max_tokens: int) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π OpenAI
    
    Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏) –∏—Å–ø–æ–ª—å–∑—É—é—Ç max_completion_tokens
    –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç max_tokens
    """
    # Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏)
    if any(model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        return {'max_completion_tokens': max_tokens}
    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (gpt-3.5-turbo, gpt-4, gpt-4o –∏ —Ç.–¥.)
    else:
        return {'max_tokens': max_tokens}

def get_api_params(model: str, messages: list, temperature: float, max_tokens: int, timeout: int) -> dict:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI API —Å —É—á–µ—Ç–æ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏
    
    Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç system —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä temperature
    """
    base_params = {
        'model': model,
        'timeout': timeout
    }
    
    # Reasoning-–º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    if any(model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        # –£–±–∏—Ä–∞–µ–º system —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π (–æ–Ω–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è)
        user_messages = [msg for msg in messages if msg.get('role') != 'system']
        if not user_messages:
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å —Ç–æ–ª—å–∫–æ system —Å–æ–æ–±—â–µ–Ω–∏—è, –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ user —Å–æ–æ–±—â–µ–Ω–∏–µ
            user_messages = [{'role': 'user', 'content': messages[-1]['content']}]
        
        base_params.update({
            'messages': user_messages,
            **get_token_params(model, max_tokens)
            # temperature –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
        })
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        base_params.update({
            'messages': messages,
            'temperature': temperature,
            **get_token_params(model, max_tokens)
        })
    
    return base_params

@chatgpt_router.callback_query(F.data == "chatgpt_mode")
async def activate_chatgpt(callback: CallbackQuery, state: FSMContext):
    """–ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ ChatGPT"""
    if not callback.message:
        return
        
    if not OPENAI_AVAILABLE:
        await callback.message.edit_text(  # type: ignore
            MESSAGES["not_configured"], 
            reply_markup=get_back_menu()
        )
        await callback.answer("–ú–æ–¥—É–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    await state.set_state(ChatGPTStates.waiting_for_message)
    
    await callback.message.edit_text(  # type: ignore
        MESSAGES["activation"],
        reply_markup=get_back_menu()
    )
    await callback.answer("ü§ñ ChatGPT –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.text)
async def handle_chatgpt_message(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è ChatGPT"""
    if not OPENAI_AVAILABLE or not openai_client or not message.text:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±–æ—Ç –¥—É–º–∞–µ—Ç
    thinking_msg = await message.reply(MESSAGES["thinking"])
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        api_messages = [
            {"role": "system", "content": "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã."},
            {"role": "user", "content": message.text}
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await thinking_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI
        await message.reply(
            f"ü§ñ **ChatGPT:**\n\n{ai_response}",
            reply_markup=get_back_menu()
        )
        
    except asyncio.TimeoutError:
        await thinking_msg.edit_text(MESSAGES["error_timeout"])
        
    except Exception as e:
        error_text = MESSAGES["error_api"].format(error=str(e))
        await thinking_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.voice)
async def handle_voice_message(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if not OPENAI_AVAILABLE or not openai_client or not message.voice:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        transcription, method, error = await transcribe_voice_message(bot, message.voice)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.video_note)
async def handle_video_note(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—É–∂–æ—á–∫–æ–≤ (–≤–∏–¥–µ–æ –∑–∞–º–µ—Ç–æ–∫)"""
    if not OPENAI_AVAILABLE or not openai_client or not message.video_note:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∫—Ä—É–∂–æ—á–µ–∫
        transcription, method, error = await transcribe_video_note(bot, message.video_note)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "‚≠ï –ö—Ä—É–∂–æ—á–µ–∫")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.audio)
async def handle_audio_file(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.audio:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
        transcription, method, error = await transcribe_audio_file(bot, message.audio)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "üéµ –ê—É–¥–∏–æ —Ñ–∞–π–ª")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

async def _process_transcribed_text(message: Message, transcription: str, audio_type: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ ChatGPT"""
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ ChatGPT –¥—É–º–∞–µ—Ç
    thinking_msg = await message.reply(MESSAGES["thinking"])
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        api_messages = [
            {"role": "system", "content": "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã."},
            {"role": "user", "content": transcription}
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await thinking_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        response_text = f"{audio_type} ‚Üí ü§ñ **ChatGPT:**\n\n"
        response_text += f"*–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:* {transcription}\n\n"
        response_text += f"*–û—Ç–≤–µ—Ç:* {ai_response}"
        
        await message.reply(response_text, reply_markup=get_back_menu())
        
    except asyncio.TimeoutError:
        await thinking_msg.edit_text(MESSAGES["error_timeout"])
        
    except Exception as e:
        error_text = MESSAGES["error_api"].format(error=str(e))
        await thinking_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message))
async def handle_unsupported_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ ChatGPT"""
    await message.reply(
        MESSAGES["unsupported_format"],
        reply_markup=get_back_menu()
    )

@chatgpt_router.callback_query(F.data == "main_menu", StateFilter(ChatGPTStates.waiting_for_message))
async def exit_chatgpt_mode(callback: CallbackQuery, state: FSMContext):
    """–í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ ChatGPT"""
    if not callback.message:
        return
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    from keyboards.main_menu import get_main_menu
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    await callback.message.edit_text("üìã –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=get_main_menu())  # type: ignore
    await callback.answer(MESSAGES["welcome_back"])

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.text.startswith("/chatgpt_info"))
async def show_module_info(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥—É–ª—è"""
    current_model = MODULE_CONFIG['model']
    effective_tokens = MODULE_CONFIG['max_tokens']
    temperature = MODULE_CONFIG['temperature']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
    if any(current_model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        temp_note = "(–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–ª—è reasoning)"
        token_note = f"(max_completion_tokens)"
        display_tokens = MODULE_CONFIG['max_completion_tokens']
    else:
        temp_note = ""
        token_note = "(max_tokens)"
        display_tokens = MODULE_CONFIG['original_max_tokens']
    
    info_text = MESSAGES["model_info"].format(
        model=current_model,
        temperature=temperature,
        temp_note=temp_note,
        max_tokens=display_tokens,
        token_note=token_note,
        whisper_mode=MODULE_CONFIG['whisper_mode'],
        whisper_language=MODULE_CONFIG['whisper_language'],
        max_size=MODULE_CONFIG['max_audio_size_mb'],
        max_duration=MODULE_CONFIG['max_audio_duration_sec'] // 60  # –í –º–∏–Ω—É—Ç–∞—Ö
    )
    
    await message.reply(info_text, reply_markup=get_back_menu())

@chatgpt_router.message(F.text.startswith("/chatgpt_info"))
async def show_module_info_outside(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥—É–ª–µ –≤–Ω–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
    if not OPENAI_AVAILABLE:
        await message.reply(MESSAGES["not_configured"])
        return
        
    current_model = MODULE_CONFIG['model']
    effective_tokens = MODULE_CONFIG['max_tokens']
    temperature = MODULE_CONFIG['temperature']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
    if any(current_model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        temp_note = "(–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–ª—è reasoning)"
        token_note = f"(max_completion_tokens)"
        display_tokens = MODULE_CONFIG['max_completion_tokens']
    else:
        temp_note = ""
        token_note = "(max_tokens)"
        display_tokens = MODULE_CONFIG['original_max_tokens']
    
    info_text = MESSAGES["model_info"].format(
        model=current_model,
        temperature=temperature,
        temp_note=temp_note,
        max_tokens=display_tokens,
        token_note=token_note,
        whisper_mode=MODULE_CONFIG['whisper_mode'],
        whisper_language=MODULE_CONFIG['whisper_language'],
        max_size=MODULE_CONFIG['max_audio_size_mb'],
        max_duration=MODULE_CONFIG['max_audio_duration_sec'] // 60  # –í –º–∏–Ω—É—Ç–∞—Ö
    )
    
    info_text += f"\n\nüí° –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –º–æ–¥—É–ª—å: /start ‚Üí ü§ñ ChatGPT"
    
    await message.reply(info_text) 