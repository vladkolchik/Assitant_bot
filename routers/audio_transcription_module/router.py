"""
–ú–æ–¥—É–ª—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ OpenAI Whisper
"""
import asyncio
import os
import tempfile
import time
from pathlib import Path
from aiogram import Router, F
from aiogram.types import CallbackQuery, Message, Audio, Voice, VideoNote, Document
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

from .config import MODULE_CONFIG, OPENAI_API_KEY
from .messages import MESSAGES

# –°–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥—É–ª—è
class AudioStates(StatesGroup):
    waiting_for_audio = State()

audio_router = Router()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = bool(OPENAI_API_KEY)
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    else:
        openai_client = None
except ImportError:
    OPENAI_AVAILABLE = False
    openai_client = None
    print("‚ö†Ô∏è OpenAI library not installed. Run: pip install openai")

def get_back_menu():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
    ])

def format_file_size(size_bytes: int) -> float:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë"""
    return round(size_bytes / (1024 * 1024), 2)

def get_file_extension(filename: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    return Path(filename).suffix.lower() if filename else ''

@audio_router.callback_query(F.data == "audio_transcription")
async def activate_transcription(callback: CallbackQuery, state: FSMContext):
    """–ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    if not callback.message:
        return
        
    if not OPENAI_AVAILABLE:
        await callback.message.edit_text(  # type: ignore
            MESSAGES["not_configured"], 
            reply_markup=get_back_menu()
        )
        await callback.answer("–ú–æ–¥—É–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –∞—É–¥–∏–æ
    await state.set_state(AudioStates.waiting_for_audio)
    
    await callback.message.edit_text(  # type: ignore
        MESSAGES["activation"],
        reply_markup=get_back_menu()
    )
    await callback.answer("üé§ –†–µ–∂–∏–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")

@audio_router.message(StateFilter(AudioStates.waiting_for_audio), F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if not OPENAI_AVAILABLE or not openai_client or not message.voice:
        return
    
    await process_audio_file(message, message.voice.file_id, "voice.ogg", message.voice.file_size)

@audio_router.message(StateFilter(AudioStates.waiting_for_audio), F.audio)
async def handle_audio_file(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.audio:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if message.audio.file_size and message.audio.file_size > MODULE_CONFIG['max_file_size']:
        size_mb = format_file_size(message.audio.file_size)
        await message.reply(
            MESSAGES["file_too_large"].format(size=size_mb),
            reply_markup=get_back_menu()
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
    filename = message.audio.file_name or "audio.mp3"
    file_ext = get_file_extension(filename)
    if file_ext not in MODULE_CONFIG['supported_formats']:
        await message.reply(
            MESSAGES["unsupported_format"].format(format=file_ext),
            reply_markup=get_back_menu()
        )
        return
    
    await process_audio_file(message, message.audio.file_id, filename, message.audio.file_size or 0)

@audio_router.message(StateFilter(AudioStates.waiting_for_audio), F.video_note)
async def handle_video_note(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—É–∂–æ—á–∫–æ–≤ (–≤–∏–¥–µ–æ—Å–æ–æ–±—â–µ–Ω–∏–π)"""
    if not OPENAI_AVAILABLE or not openai_client or not message.video_note:
        return
    
    await process_audio_file(message, message.video_note.file_id, "video_note.mp4", message.video_note.file_size or 0)

@audio_router.message(StateFilter(AudioStates.waiting_for_audio), F.document)
async def handle_document_audio(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.document:
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª
    filename = message.document.file_name or ""
    file_ext = get_file_extension(filename)
    if file_ext not in MODULE_CONFIG['supported_formats']:
        await message.reply(
            "üìé –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.\n\n" + MESSAGES["help"],
            reply_markup=get_back_menu()
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if message.document.file_size and message.document.file_size > MODULE_CONFIG['max_file_size']:
        size_mb = format_file_size(message.document.file_size)
        await message.reply(
            MESSAGES["file_too_large"].format(size=size_mb),
            reply_markup=get_back_menu()
        )
        return
    
    await process_audio_file(message, message.document.file_id, filename, message.document.file_size or 0)

async def process_audio_file(message: Message, file_id: str, filename: str, file_size: int):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
    start_time = time.time()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
    processing_msg = await message.reply(MESSAGES["processing"])
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –æ—Ç Telegram
        file_info = await message.bot.get_file(file_id)
        if not file_info.file_path:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        file_ext = get_file_extension(filename)
        with tempfile.NamedTemporaryFile(suffix=file_ext, delete=False) as temp_file:
            temp_path = temp_file.name
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            await message.bot.download_file(file_info.file_path, temp_path)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        await processing_msg.edit_text(MESSAGES["transcribing"])
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Whisper API
        with open(temp_path, 'rb') as audio_file:
            language = MODULE_CONFIG['language'] if MODULE_CONFIG['language'] != 'auto' else None
            
            transcription = await asyncio.to_thread(
                openai_client.audio.transcriptions.create,  # type: ignore
                model=MODULE_CONFIG['model'],
                file=audio_file,
                language=language,
                temperature=MODULE_CONFIG['temperature']
            )
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(temp_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not transcription.text or transcription.text.strip() == "":
            await processing_msg.edit_text(
                MESSAGES["no_speech"],
                reply_markup=get_back_menu()
            )
            return
        
        # –ì–æ—Ç–æ–≤–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        duration = round(time.time() - start_time, 1)
        file_size_mb = format_file_size(file_size)
        detected_language = getattr(transcription, 'language', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        
        result_text = MESSAGES["success"].format(
            transcription=transcription.text.strip(),
            duration=duration,
            language=detected_language,
            file_size=file_size_mb
        )
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é..."
        await processing_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await message.reply(
            result_text,
            reply_markup=get_back_menu()
        )
        
    except asyncio.TimeoutError:
        await processing_msg.edit_text(
            MESSAGES["error_timeout"],
            reply_markup=get_back_menu()
        )
        
    except Exception as e:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        try:
            if 'temp_path' in locals():
                os.unlink(temp_path)
        except:
            pass
        
        error_text = str(e)
        if "download" in error_text.lower():
            await processing_msg.edit_text(
                MESSAGES["error_download"].format(error=error_text),
                reply_markup=get_back_menu()
            )
        elif "api" in error_text.lower() or "openai" in error_text.lower():
            await processing_msg.edit_text(
                MESSAGES["error_api"].format(error=error_text),
                reply_markup=get_back_menu()
            )
        else:
            await processing_msg.edit_text(
                MESSAGES["error_general"].format(error=error_text),
                reply_markup=get_back_menu()
            )

@audio_router.message(StateFilter(AudioStates.waiting_for_audio))
async def handle_non_audio_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ-–∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    await message.reply(
        "üé§ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.\n\n" + MESSAGES["help"],
        reply_markup=get_back_menu()
    )

@audio_router.callback_query(F.data == "main_menu", StateFilter(AudioStates.waiting_for_audio))
async def exit_transcription_mode(callback: CallbackQuery, state: FSMContext):
    """–í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    if not callback.message:
        return
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    from keyboards.main_menu import get_main_menu
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    await callback.message.edit_text("üìã –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=get_main_menu())
    await callback.answer(MESSAGES["welcome_back"]) 