"""
ChatGPT + Whisper –º–æ–¥—É–ª—å –¥–ª—è Telegram –±–æ—Ç–∞
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI API –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∞—É–¥–∏–æ
"""
import asyncio
from aiogram import Router, F, Bot
from aiogram.types import CallbackQuery, Message
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

from .config import MODULE_CONFIG, OPENAI_API_KEY
from .messages import MESSAGES
from .services import transcribe_voice_message, transcribe_video_note, transcribe_audio_file
from .image_utils import create_image_processor
from .memory_service import memory_service

# –°–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥—É–ª—è
class ChatGPTStates(StatesGroup):
    waiting_for_message = State()

chatgpt_router = Router()

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = bool(OPENAI_API_KEY)
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
    else:
        openai_client = None
except ImportError:
    OPENAI_AVAILABLE = False
    openai_client = None
    print("‚ö†Ô∏è OpenAI library not installed. Run: pip install openai")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
try:
    if MODULE_CONFIG['vision_enabled']:
        image_processor = create_image_processor(MODULE_CONFIG)
        VISION_AVAILABLE = True
    else:
        image_processor = None
        VISION_AVAILABLE = False
except ImportError:
    print("‚ö†Ô∏è PIL (Pillow) library not installed. Vision API disabled. Run: pip install Pillow")
    image_processor = None
    VISION_AVAILABLE = False

def get_back_menu():
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é"""
    keyboard = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏ –µ—Å–ª–∏ Mem0 –≤–∫–ª—é—á–µ–Ω
    if MODULE_CONFIG.get('mem0_enabled', False):
        keyboard.append([InlineKeyboardButton(text="üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å", callback_data="clear_memory")])
    
    # –ö–Ω–æ–ø–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    keyboard.append([InlineKeyboardButton(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")])
    
    return InlineKeyboardMarkup(inline_keyboard=keyboard)

def get_token_params(model: str, max_tokens: int) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π OpenAI
    
    Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏) –∏—Å–ø–æ–ª—å–∑—É—é—Ç max_completion_tokens
    –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç max_tokens
    """
    # Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏)
    if any(model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        return {'max_completion_tokens': max_tokens}
    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (gpt-3.5-turbo, gpt-4, gpt-4o –∏ —Ç.–¥.)
    else:
        return {'max_tokens': max_tokens}

def get_api_params(model: str, messages: list, temperature: float, max_tokens: int, timeout: int) -> dict:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—ã–∑–æ–≤–∞ OpenAI API —Å —É—á–µ—Ç–æ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–∏
    
    Reasoning-–º–æ–¥–µ–ª–∏ (o1, o3, o4 —Å–µ—Ä–∏–∏) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç system —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä temperature
    """
    base_params = {
        'model': model,
        'timeout': timeout
    }
    
    # Reasoning-–º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    if any(model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        # –£–±–∏—Ä–∞–µ–º system —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π (–æ–Ω–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è)
        user_messages = [msg for msg in messages if msg.get('role') != 'system']
        if not user_messages:
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å —Ç–æ–ª—å–∫–æ system —Å–æ–æ–±—â–µ–Ω–∏—è, –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ user —Å–æ–æ–±—â–µ–Ω–∏–µ
            user_messages = [{'role': 'user', 'content': messages[-1]['content']}]
        
        base_params.update({
            'messages': user_messages,
            **get_token_params(model, max_tokens)
            # temperature –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
        })
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        base_params.update({
            'messages': messages,
            'temperature': temperature,
            **get_token_params(model, max_tokens)
        })
    
    return base_params

@chatgpt_router.callback_query(F.data == "chatgpt_mode")
async def activate_chatgpt(callback: CallbackQuery, state: FSMContext):
    """–ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ ChatGPT"""
    if not callback.message:
        return
        
    if not OPENAI_AVAILABLE:
        await callback.message.edit_text(  # type: ignore
            MESSAGES["not_configured"], 
            reply_markup=get_back_menu()
        )
        await callback.answer("–ú–æ–¥—É–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    await state.set_state(ChatGPTStates.waiting_for_message)
    
    await callback.message.edit_text(  # type: ignore
        MESSAGES["activation"],
        reply_markup=get_back_menu()
    )
    await callback.answer("ü§ñ ChatGPT –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!")

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.text)
async def handle_chatgpt_message(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è ChatGPT"""
    if not OPENAI_AVAILABLE or not openai_client or not message.text:
        return
    
    if not message.from_user:
        return
        
    user_id = str(message.from_user.id)
    user_text = message.text
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±–æ—Ç –¥—É–º–∞–µ—Ç
    thinking_msg = await message.reply(MESSAGES["thinking"])
    
    try:
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏
        memory_context = ""
        context_count = 0
        
        if MODULE_CONFIG.get('mem0_enabled', False):
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è
                memory_context = await memory_service.search_relevant_memories(user_id, user_text, limit=3)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                user_profile = await memory_service.get_user_profile(user_id)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                full_context_parts = []
                if user_profile:
                    full_context_parts.append(user_profile)
                if memory_context:
                    full_context_parts.append(memory_context)
                
                memory_context = "\n\n".join(full_context_parts)
                
                if memory_context:
                    context_count = len(memory_context.split('\n')) - 1  # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
                    # print(f"üß† –ó–∞–≥—Ä—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏ –¥–ª—è {user_id}: {context_count} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π")
                    # print(f"üîç –û–¢–õ–ê–î–ö–ê - –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {memory_context}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –ø–∞–º—è—Ç–∏: {e}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        system_content = "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã."
        
        # –î–ª—è reasoning-–º–æ–¥–µ–ª–µ–π –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        user_content = user_text
        if memory_context:
            user_content = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤:\n{memory_context}\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_text}"
        
        api_messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content}
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await thinking_msg.delete()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞–º—è—Ç–∏
        response_text = f"ü§ñ **ChatGPT:**\n\n{ai_response}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        if MODULE_CONFIG.get('mem0_enabled', False) and context_count > 0:
            response_text += f"\n\n{MESSAGES['memory_context_loaded'].format(count=context_count)}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI
        await message.reply(response_text, reply_markup=get_back_menu())
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥ –≤ –ø–∞–º—è—Ç—å
        if MODULE_CONFIG.get('mem0_enabled', False):
            try:
                conversation = [
                    {"role": "user", "content": user_text},
                    {"role": "assistant", "content": ai_response}
                ]
                # print(f"üíæ –û–¢–õ–ê–î–ö–ê - –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å: {conversation}")
                await memory_service.add_conversation(user_id, conversation)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç—å: {e}")
        
    except asyncio.TimeoutError:
        await thinking_msg.edit_text(MESSAGES["error_timeout"])
        
    except Exception as e:
        error_text = MESSAGES["error_api"].format(error=str(e))
        await thinking_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.voice)
async def handle_voice_message(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if not OPENAI_AVAILABLE or not openai_client or not message.voice:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        transcription, method, error = await transcribe_voice_message(bot, message.voice)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.video_note)
async def handle_video_note(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—É–∂–æ—á–∫–æ–≤ (–≤–∏–¥–µ–æ –∑–∞–º–µ—Ç–æ–∫)"""
    if not OPENAI_AVAILABLE or not openai_client or not message.video_note:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∫—Ä—É–∂–æ—á–µ–∫
        transcription, method, error = await transcribe_video_note(bot, message.video_note)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "‚≠ï –ö—Ä—É–∂–æ—á–µ–∫")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.audio)
async def handle_audio_file(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    if not OPENAI_AVAILABLE or not openai_client or not message.audio:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
    processing_msg = await message.reply(MESSAGES["processing_audio"])
    
    try:
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
        transcription, method, error = await transcribe_audio_file(bot, message.audio)
        
        if error:
            await processing_msg.edit_text(MESSAGES["audio_error"].format(error=error))
            return
        
        if not transcription:
            await processing_msg.edit_text(MESSAGES["no_speech_detected"])
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏
        await processing_msg.edit_text(MESSAGES["transcription_success"].format(
            method=method, 
            text=transcription[:100] + ("..." if len(transcription) > 100 else "")
        ))
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ ChatGPT
        await _process_transcribed_text(message, transcription, "üéµ –ê—É–¥–∏–æ —Ñ–∞–π–ª")
        
    except Exception as e:
        await processing_msg.edit_text(MESSAGES["audio_error"].format(error=str(e)))

async def _process_transcribed_text(message: Message, transcription: str, audio_type: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ ChatGPT"""
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ ChatGPT –¥—É–º–∞–µ—Ç
    thinking_msg = await message.reply(MESSAGES["thinking"])
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        api_messages = [
            {"role": "system", "content": "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã."},
            {"role": "user", "content": transcription}
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ "–î—É–º–∞—é..."
        await thinking_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        response_text = f"{audio_type} ‚Üí ü§ñ **ChatGPT:**\n\n"
        response_text += f"*–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:* {transcription}\n\n"
        response_text += f"*–û—Ç–≤–µ—Ç:* {ai_response}"
        
        await message.reply(response_text, reply_markup=get_back_menu())
        
    except asyncio.TimeoutError:
        await thinking_msg.edit_text(MESSAGES["error_timeout"])
        
    except Exception as e:
        error_text = MESSAGES["error_api"].format(error=str(e))
        await thinking_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.photo)
async def handle_image_message(message: Message, bot: Bot, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Vision API"""
    if not OPENAI_AVAILABLE or not openai_client or not message.photo:
        return
    
    if not VISION_AVAILABLE or not image_processor:
        await message.reply(
            "üì∑ **Vision API –æ—Ç–∫–ª—é—á–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω**\n\n"
            "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            "‚Ä¢ –ú–æ–¥—É–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n"
            "‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Vision API\n"
            "‚Ä¢ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ PIL\n\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏: gpt-4o, gpt-4o-mini, gpt-4-vision-preview",
            reply_markup=get_back_menu()
        )
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    processing_msg = await message.reply("üñºÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        # –ë–µ—Ä–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–∏–≤—ã—Å—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        photo = message.photo[-1]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        file_stream = await bot.download(photo)  # type: ignore
        if not file_stream:
            await processing_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            return
        
        image_bytes = file_stream.read()  # type: ignore
        file_stream.close()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è API
        base64_image, image_info = image_processor.prepare_image_for_api(
                            image_bytes, MODULE_CONFIG['vision_quality']
        )
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if MODULE_CONFIG['vision_cost_warnings']:
            cost_warning = image_processor.get_cost_warning(image_info, MODULE_CONFIG['model'])
            await processing_msg.edit_text(
                f"üñºÔ∏è **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:**\n\n{cost_warning}\n\nü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é..."
            )
        else:
            await processing_msg.edit_text("ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Vision API
        user_text = message.caption if message.caption else "–û–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –≤–∏–¥–∏—Ç–µ –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."
        
        api_messages = [
            {
                "role": "system", 
                "content": "–í—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã –∏ –ø–æ–¥—Ä–æ–±–Ω—ã –≤ –æ–ø–∏—Å–∞–Ω–∏—è—Ö."
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_text},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                            "detail": MODULE_CONFIG['vision_quality']
                        }
                    }
                ]
            }
        ]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏ (–±–µ–∑ temperature –¥–ª—è reasoning –º–æ–¥–µ–ª–µ–π)
        api_params = get_api_params(
            model=MODULE_CONFIG['model'],
            messages=api_messages,
            temperature=MODULE_CONFIG['temperature'],
            max_tokens=MODULE_CONFIG['max_tokens'],
            timeout=MODULE_CONFIG['timeout']
        )
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ Vision API
        response = await asyncio.to_thread(
            openai_client.chat.completions.create,  # type: ignore
            **api_params
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        ai_response = response.choices[0].message.content
        if ai_response:
            ai_response = ai_response.strip()
        else:
            ai_response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        await processing_msg.delete()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        response_text = f"üñºÔ∏è **Vision API:**\n\n"
        if message.caption:
            response_text += f"*–í–∞—à –≤–æ–ø—Ä–æ—Å:* {message.caption}\n\n"
        response_text += f"*–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:* {ai_response}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö –≤ –∫–æ–Ω—Ü–µ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if MODULE_CONFIG['vision_cost_warnings']:
            estimated_cost = image_processor.estimate_cost_usd(image_info['estimated_tokens'], MODULE_CONFIG['model'])
            response_text += f"\n\nüí∞ *–ó–∞—Ç—Ä–∞—á–µ–Ω–æ: ~${estimated_cost:.4f} (~{image_info['estimated_tokens']} —Ç–æ–∫–µ–Ω–æ–≤)*"
        
        await message.reply(response_text, reply_markup=get_back_menu())
        
    except Exception as e:
        error_text = f"‚ùå **–û—à–∏–±–∫–∞ Vision API:**\n{str(e)}\n\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n‚Ä¢ –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç API\n‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        await processing_msg.edit_text(error_text)

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message))
async def handle_unsupported_message(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–µ–∂–∏–º–µ ChatGPT"""
    await message.reply(
        MESSAGES["unsupported_format"],
        reply_markup=get_back_menu()
    )

@chatgpt_router.callback_query(F.data == "clear_memory", StateFilter(ChatGPTStates.waiting_for_message))
async def clear_user_memory(callback: CallbackQuery):
    """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if not callback.message:
        return
    
    user_id = str(callback.from_user.id)
    
    if not MODULE_CONFIG.get('mem0_enabled', False):
        await callback.answer(MESSAGES["memory_disabled"])
        return
    
    try:
        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        success = await memory_service.clear_user_memory(user_id)
        
        if success:
            await callback.message.edit_text(  # type: ignore
                MESSAGES["memory_cleared"],
                reply_markup=get_back_menu()
            )
            await callback.answer("üóëÔ∏è –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞!")
        else:
            await callback.message.edit_text(  # type: ignore
                MESSAGES["memory_clear_error"],
                reply_markup=get_back_menu()
            )
            await callback.answer("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
        await callback.message.edit_text(  # type: ignore
            MESSAGES["memory_clear_error"],
            reply_markup=get_back_menu()
        )
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏")

@chatgpt_router.callback_query(F.data == "main_menu", StateFilter(ChatGPTStates.waiting_for_message))
async def exit_chatgpt_mode(callback: CallbackQuery, state: FSMContext):
    """–í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ ChatGPT"""
    if not callback.message:
        return
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    from keyboards.main_menu import get_main_menu
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    await callback.message.edit_text("üìã –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=get_main_menu())  # type: ignore
    await callback.answer(MESSAGES["welcome_back"])

@chatgpt_router.message(StateFilter(ChatGPTStates.waiting_for_message), F.text.startswith("/chatgpt_info"))
async def show_module_info(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥—É–ª—è"""
    current_model = MODULE_CONFIG['model']
    effective_tokens = MODULE_CONFIG['max_tokens']
    temperature = MODULE_CONFIG['temperature']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
    if any(current_model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        temp_note = "(–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–ª—è reasoning)"
        token_note = f"(max_completion_tokens)"
        display_tokens = MODULE_CONFIG['max_completion_tokens']
    else:
        temp_note = ""
        token_note = "(max_tokens)"
        display_tokens = MODULE_CONFIG['original_max_tokens']
    
    info_text = MESSAGES["model_info"].format(
        model=current_model,
        temperature=temperature,
        temp_note=temp_note,
        max_tokens=display_tokens,
        token_note=token_note,
        whisper_mode=MODULE_CONFIG['whisper_mode'],
        whisper_language=MODULE_CONFIG['whisper_language'],
        max_size=MODULE_CONFIG['max_audio_size_mb'],
        max_duration=MODULE_CONFIG['max_audio_duration_sec'] // 60  # –í –º–∏–Ω—É—Ç–∞—Ö
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Mem0 –ø–∞–º—è—Ç–∏
    if MODULE_CONFIG.get('mem0_enabled', False):
        memory_stats = memory_service.get_memory_stats()
        memory_status = "‚úÖ –í–∫–ª—é—á–µ–Ω–∞" if memory_stats.get('enabled', False) else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
        memory_provider = memory_stats.get('provider', 'N/A')
        
        info_text += f"\n\n**Mem0 –ü–∞–º—è—Ç—å:**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {memory_status}\n"
        info_text += f"‚Ä¢ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {memory_provider}"
    else:
        info_text += f"\n\n**Mem0 –ü–∞–º—è—Ç—å:** ‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
    
    await message.reply(info_text, reply_markup=get_back_menu())

@chatgpt_router.message(F.text.startswith("/chatgpt_info"))
async def show_module_info_outside(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥—É–ª–µ –≤–Ω–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
    if not OPENAI_AVAILABLE:
        await message.reply(MESSAGES["not_configured"])
        return
        
    current_model = MODULE_CONFIG['model']
    effective_tokens = MODULE_CONFIG['max_tokens']
    temperature = MODULE_CONFIG['temperature']
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–º–µ—Ç–∫–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è reasoning-–º–æ–¥–µ–ª–µ–π
    if any(current_model.startswith(prefix) for prefix in ['o1-', 'o3-', 'o4-']):
        temp_note = "(–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è –¥–ª—è reasoning)"
        token_note = f"(max_completion_tokens)"
        display_tokens = MODULE_CONFIG['max_completion_tokens']
    else:
        temp_note = ""
        token_note = "(max_tokens)"
        display_tokens = MODULE_CONFIG['original_max_tokens']
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ Vision API –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –≤—ã–∑–æ–≤–∞
    vision_status = "‚úÖ –í–∫–ª—é—á–µ–Ω" if MODULE_CONFIG['vision_enabled'] and VISION_AVAILABLE else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω"
    vision_quality = MODULE_CONFIG['vision_quality'] if MODULE_CONFIG['vision_enabled'] else "N/A"
    
    info_text = MESSAGES["model_info"].format(
        model=current_model,
        temperature=temperature,
        temp_note=temp_note,
        max_tokens=display_tokens,
        token_note=token_note,
        whisper_mode=MODULE_CONFIG['whisper_mode'],
        whisper_language=MODULE_CONFIG['whisper_language'],
        max_size=MODULE_CONFIG['max_audio_size_mb'],
        max_duration=MODULE_CONFIG['max_audio_duration_sec'] // 60  # –í –º–∏–Ω—É—Ç–∞—Ö
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Vision API
    info_text += f"\n\n**Vision API (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è):**\n"
    info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {vision_status}\n"
    info_text += f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ: {vision_quality}\n"
    info_text += f"‚Ä¢ –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {MODULE_CONFIG['max_image_size_mb']} –ú–ë\n"
    info_text += f"‚Ä¢ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –∑–∞—Ç—Ä–∞—Ç–∞—Ö: {'‚úÖ' if MODULE_CONFIG['vision_cost_warnings'] else '‚ùå'}"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Mem0 –ø–∞–º—è—Ç–∏
    if MODULE_CONFIG.get('mem0_enabled', False):
        memory_stats = memory_service.get_memory_stats()
        memory_status = "‚úÖ –í–∫–ª—é—á–µ–Ω–∞" if memory_stats.get('enabled', False) else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
        memory_provider = memory_stats.get('provider', 'N/A')
        
        info_text += f"\n\n**Mem0 –ü–∞–º—è—Ç—å:**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {memory_status}\n"
        info_text += f"‚Ä¢ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {memory_provider}\n"
        info_text += f"‚Ä¢ –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤"
    else:
        info_text += f"\n\n**Mem0 –ü–∞–º—è—Ç—å:**\n"
        info_text += f"‚Ä¢ –°—Ç–∞—Ç—É—Å: ‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞\n"
        info_text += f"‚Ä¢ –î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ MEM0_API_KEY –≤ .env"
    
    info_text += f"\n\nüí° –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –º–æ–¥—É–ª—å: /start ‚Üí ü§ñ ChatGPT"
    
    await message.reply(info_text) 